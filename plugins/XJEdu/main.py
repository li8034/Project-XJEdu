import asyncio
import json
import os
import re
import sys
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from astrbot.api.event import filter, AstrMessageEvent, MessageChain
from astrbot.api.star import Context, Star, register
from astrbot.api import logger

try:
    from bs4 import BeautifulSoup  # å·²åœ¨ AstrBot ä¾èµ–ä¸­
except Exception:  # pragma: no cover
    BeautifulSoup = None

try:
    import aiohttp  # å·²åœ¨ AstrBot ä¾èµ–ä¸­
except Exception:  # pragma: no cover
    aiohttp = None

try:
    from playwright.async_api import async_playwright  # å¯é€‰ä¾èµ–ï¼Œç”¨äºç»•è¿‡åŠ¨æ€æŒ‘æˆ˜
except Exception:  # pragma: no cover
    async_playwright = None


DUE_LIST_URL = "https://due.xjtu.edu.cn/jxxx/jxtz2.htm"
DUE_LIST_EXTRA = [
    "https://due.xjtu.edu.cn/jxxx/jxtz2/jsap.htm",  # ç«èµ›å®‰æ’å­æ ç›®
    "https://due.xjtu.edu.cn/jxxx/jxtz2/jsdc.htm",  # ç«èµ›å¤§åˆ›å­æ ç›®
]
STORE_PATH = os.path.join(os.path.dirname(__file__), "competitions_store.json")


def _now() -> datetime:
    return datetime.now()


def _parse_date(date_str: str) -> Optional[datetime]:
    date_str = date_str.strip()
    date_str = date_str.replace("â€”", "-").replace("â€“", "-").replace("è‡³", "-").replace("~", "-").replace("ï½", "-")
    patterns = [
        "%Yå¹´%mæœˆ%dæ—¥",
        "%Y-%m-%d",
        "%Y/%m/%d",
        "%Y.%m.%d",
    ]
    for p in patterns:
        try:
            return datetime.strptime(date_str, p)
        except Exception:
            pass
    # ä¸­æ–‡å¸¦æ—¶åˆ†çš„ç®€å•å¤„ç†
    m = re.search(r"(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥", date_str)
    if m:
        try:
            y, mo, d = int(m.group(1)), int(m.group(2)), int(m.group(3))
            return datetime(y, mo, d)
        except Exception:
            return None
    m2 = re.search(r"(\d{4})[./-](\d{1,2})[./-](\d{1,2})", date_str)
    if m2:
        try:
            y, mo, d = int(m2.group(1)), int(m2.group(2)), int(m2.group(3))
            return datetime(y, mo, d)
        except Exception:
            return None
    return None


def _extract_qq_group(text: str) -> Optional[str]:
    patterns = [
        r"QQç¾¤[å·]?[ï¼š: ]?(\d{5,12})",
        r"QQ[ï¼š: ]?(\d{5,12})",
        r"ç¾¤å·[ï¼š: ]?(\d{5,12})",
    ]
    for pat in patterns:
        m = re.search(pat, text, flags=re.IGNORECASE)
        if m:
            return m.group(1)
    return None


def _is_registration(title: str, body: str) -> bool:
    kw = [
        "æŠ¥å", "æŠ¥åé€šçŸ¥", "æŠ¥åå¼€å§‹", "æŠ¥åæˆªæ­¢", "æŠ¥åé“¾æ¥", "å‚èµ›", "ç«èµ›æŠ¥å",
        "ç«èµ›å®‰æ’", "èµ›äº‹å®‰æ’", "ç«èµ›é€šçŸ¥"
    ]
    text = f"{title}\n{body}"
    return any(k in text for k in kw)


def _extract_time_window(body: str) -> Dict[str, Optional[datetime]]:
    res: Dict[str, Optional[datetime]] = {"start": None, "end": None}
    range_pat = re.search(r"(\d{4}[å¹´./-]\d{1,2}[æœˆ./-]\d{1,2})\s*[â€”â€“\-~ï½è‡³åˆ°]{1,2}\s*(\d{4}[å¹´./-]\d{1,2}[æœˆ./-]\d{1,2})", body)
    if range_pat:
        s_dt = _parse_date(range_pat.group(1))
        e_dt = _parse_date(range_pat.group(2))
        if s_dt:
            res["start"] = s_dt
        if e_dt:
            res["end"] = e_dt
    # å°è¯•ä»â€œå¼€å§‹æ—¶é—´/æˆªæ­¢æ—¶é—´/æŠ¥åæ—¶é—´â€è¡Œä¸­æå–
    pairs = [
        (r"å¼€å§‹(?:æ—¶é—´|æ—¥æœŸ)[ï¼š: ]*(.+)", "start"),
        (r"æˆªæ­¢(?:æ—¶é—´|æ—¥æœŸ)[ï¼š: ]*(.+)", "end"),
        (r"æŠ¥å(?:å¼€å§‹)?(?:æ—¶é—´|æ—¥æœŸ)[ï¼š: ]*(.+)", "start"),
        (r"æŠ¥åæˆªæ­¢(?:æ—¶é—´|æ—¥æœŸ)?[ï¼š: ]*(.+)", "end"),
    ]
    for pat, key in pairs:
        m = re.search(pat, body)
        if m:
            dt = _parse_date(m.group(1))
            if dt:
                res[key] = dt

    # è‹¥æ— è¡ŒåŒ¹é…ï¼Œå°è¯•æŠ“å–æ®µè½ä¸­çš„ä¸¤ä¸ªæ—¥æœŸï¼Œä»¥ç¬¬ä¸€ä¸ªå½“ startï¼Œæœ€åä¸€ä¸ªå½“ end
    dates = re.findall(r"\d{4}[./-]\d{1,2}[./-]\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥", body)
    parsed = [d for d in (_parse_date(s) for s in dates) if d]
    if parsed:
        parsed.sort()
        if res["start"] is None:
            res["start"] = parsed[0]
        if res["end"] is None:
            res["end"] = parsed[-1]
    return res


@register("xjedu_competition", "U_Miyako", "è¥¿äº¤æ•™åŠ¡ç«èµ›ç›‘æ§ä¸æ¨é€", "0.1.0")
class XJEduPlugin(Star):
    def __init__(self, context: Context):
        super().__init__(context)
        self._running = True
        self._check_task: Optional[asyncio.Task] = None
        self._remind_task: Optional[asyncio.Task] = None
        self.ai_conf: Dict[str, Any] = {}
        self.store_loaded = False
        self._challenge_warned = False
        self._render_dumped = False

    def _persona_wrap(self, text: str) -> str:
        """å°†è¾“å‡ºæ–‡æœ¬æŒ‰å†…å‘çŒ«å¨˜å£ç™–è¿›è¡ŒåŒ…è£…ï¼Œä»…å½±å“èŠå¤©è¾“å‡ºï¼Œä¸æ”¹åŠ¨æ—¥å¿—ä¸æ–‡ä»¶ã€‚"""
        lines = (text or "").splitlines()
        wrapped: List[str] = []
        for ln in lines:
            s = ln.rstrip()
            if not s:
                wrapped.append(ln)
                continue
            # å·²å¸¦æœ‰å£ç™–åˆ™ä¸é‡å¤è¿½åŠ 
            if s.endswith("å–µï½") or s.endswith("å–µ~"):
                wrapped.append(s)
            else:
                wrapped.append(s + "å–µï½")
        return "\n".join(wrapped)

    async def initialize(self):
        # è¯»å– AI é…ç½®
        await self._load_ai_config()
        # å¯åŠ¨æ—¶è¾“å‡ºè§£é‡Šå™¨ä¸ Playwright çŠ¶æ€ï¼Œæ–¹ä¾¿æ’æŸ¥è¿è¡Œç¯å¢ƒ
        # åˆå§‹åŒ– AI å¼€å…³ï¼ˆKV æœªè®¾å®šåˆ™é‡‡ç”¨é…ç½®é»˜è®¤å€¼ï¼‰
        if (await self.get_kv_data("ai_use", None)) is None:
            await self._save_kv("ai_use", bool(self.ai_conf.get("use_ai", False)))
        # å…ˆå°è¯•ä»å¤–ç½®æ–‡ä»¶æ¢å¤å†å²çŸ¥è¯†åº“ï¼Œå‡å°‘äºŒæ¬¡æ‹‰å–ï¼›åˆå§‹åŒ–åŒæ­¥æ”¹ä¸ºæ‰‹åŠ¨æŒ‡ä»¤è§¦å‘
        await self._load_store_file()
        # å¯åŠ¨å®šæ—¶ä»»åŠ¡ï¼šæ¯30åˆ†é’Ÿæ‹‰å–ä¸€æ¬¡ï¼›æ¯æ—¥æé†’ä¸€æ¬¡
        self._check_task = asyncio.create_task(self._periodic_check_loop(interval_sec=1800))
        self._remind_task = asyncio.create_task(self._daily_deadline_remind_loop(hour=9))
        # å¯åŠ¨æ—¶ä¸åšä»»ä½•æŠ“å–ï¼Œä»…åŠ è½½æœ¬åœ°æ–‡ä»¶ä¸å¯åŠ¨ä»»åŠ¡
        logger.info("[XJEdu] ç«èµ›ç›‘æ§æ’ä»¶å·²å¯åŠ¨")

    async def terminate(self):
        self._running = False
        for t in [self._check_task, self._remind_task]:
            if t and not t.done():
                t.cancel()
        logger.info("[XJEdu] ç«èµ›ç›‘æ§æ’ä»¶å·²åœæ­¢")

    async def _stop_check_task(self):
        # ä»…åœæ­¢å½“å‰æ­£åœ¨è¿è¡Œçš„æ£€æŸ¥ä»»åŠ¡ï¼Œä¸å½±å“åç»­å®šæ—¶è°ƒåº¦
        if self._check_task and not self._check_task.done():
            self._check_task.cancel()
            self._check_task = None
            logger.info("[XJEdu] å·²åœæ­¢å½“å‰æ£€æŸ¥ä»»åŠ¡")
        else:
            logger.info("[XJEdu] å½“å‰æ— æ­£åœ¨æ‰§è¡Œçš„æ£€æŸ¥ä»»åŠ¡")

    async def _load_ai_config(self):
        try:
            # ç‹¬ç«‹é…ç½®æ–‡ä»¶ï¼šplugins/XJEdu/config_ai.json
            conf_path = os.path.join(os.path.dirname(__file__), "config_ai.json")
            if os.path.exists(conf_path):
                with open(conf_path, "r", encoding="utf-8") as f:
                    self.ai_conf = json.load(f)
            else:
                self.ai_conf = {
                    "use_ai": True,
                    "provider": "deepseek",
                    "base_url": "https://api.deepseek.com",
                    "api_key": "",
                    "model": "deepseek-chat",
                }
        except Exception as e:
            logger.warning(f"[XJEdu] è¯»å–AIé…ç½®å¤±è´¥: {e}")
            self.ai_conf = {"use_ai": True}

    async def _get_kv(self, key: str, default: Any):
        v = await self.get_kv_data(key, default)
        return v if v is not None else default

    async def _save_kv(self, key: str, value: Any):
        await self.put_kv_data(key, value)

    async def _is_ai_enabled(self) -> bool:
        flag = await self._get_kv("ai_use", None)
        if flag is None:
            return bool(self.ai_conf.get("use_ai", False))
        return bool(flag)

    async def _ai_extract_competition(self, title: str, body: str, raw_html: Optional[str] = None) -> Optional[Dict[str, Any]]:
        if not await self._is_ai_enabled():
            return None
        if not aiohttp:
            logger.warning("[XJEdu] AI è§£æéœ€è¦ aiohttpï¼Œå¯é€‰å®‰è£…åå†è¯•")
            return None
        api_key = (self.ai_conf or {}).get("api_key")
        if not api_key:
            logger.warning("[XJEdu] AI è§£ææœªé…ç½® api_keyï¼Œå·²è·³è¿‡")
            return None
        base_url = (self.ai_conf or {}).get("base_url", "https://api.deepseek.com").rstrip("/")
        model = (self.ai_conf or {}).get("model", "deepseek-chat")
        url = f"{base_url}/chat/completions"
        prompt_text = (
            "è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹è¦æ±‚æå–ï¼š\n"
            "- åˆ¤æ–­æ˜¯å¦ä¸ºç«èµ›æŠ¥å/å‚èµ›é€šçŸ¥ï¼›\n"
            "- ä»…å½“ä¸ºæŠ¥å/å‚èµ›é€šçŸ¥æ—¶ï¼Œæå–ç«èµ›æŠ¥åå¼€å§‹æ—¥æœŸã€æŠ¥åæˆªæ­¢æ—¥æœŸï¼›\n"
            "- è¾“å‡ºä¸¥æ ¼ JSONï¼š{\"is_registration\": bool, \"start_date\": æ—¥æœŸæˆ–null, \"end_date\": æ—¥æœŸæˆ–null}ï¼›\n"
            "- æ—¥æœŸæ ¼å¼ YYYY-MM-DDï¼›\n"
            "- è‹¥éæŠ¥åé€šçŸ¥ï¼Œåˆ™ is_registration=false ä¸” start_date/end_date ä¸º nullï¼›\n"
            "- åªå–æŠ¥åæ—¶é—´ï¼Œå¿½ç•¥ä¸¾åŠ/å¼€èµ›/æ´»åŠ¨/è¯„å®¡/ç­”è¾©/åŸ¹è®­/è®²åº§/ä½œå“æäº¤ç­‰éæŠ¥åæ—¶é—´ï¼›\n"
            "- å¦‚ä»…å‡ºç°å•ä¸€æ—¥æœŸæˆ–æ— æ³•ç¡®å®šï¼Œç¼ºå¤±å­—æ®µå¡« nullï¼›\n"
            "- ä¸è¦è¾“å‡ºå¤šä½™æ–‡å­—ï¼Œä¸è¦ä»£ç å—ã€‚"
        )
        # è‹¥æ£€æµ‹åˆ°åŠ¨æ€éªŒè¯é¡µé¢ï¼Œé¿å…å°†å…¶å‘ç»™ AI
        if raw_html and ("dynamic_challenge" in raw_html or "å®‰å…¨æ£€æŸ¥" in raw_html):
            raw_html = None
        # ä¼˜å…ˆä½¿ç”¨æ•´é¡µ HTMLï¼ˆä¸æˆªæ–­ï¼‰ï¼Œå¹¶è½ç›˜ä¾›æ£€æŸ¥ï¼›æ—  HTML æ—¶é€€å›æ­£æ–‡ç‰‡æ®µ
        if raw_html:
            lines = [f"æ ‡é¢˜ï¼š{title}"]
            lines.append("ç½‘é¡µHTMLå…¨æ–‡ï¼ˆæœªæˆªæ–­ï¼‰ï¼š")
            lines.append(raw_html)
            user_content = "\n".join([prompt_text] + lines)
            dump_path = os.path.join(os.path.dirname(__file__), "ai_input_last.html")
            try:
                with open(dump_path, "w", encoding="utf-8", errors="ignore") as f:
                    f.write(raw_html)
            except Exception as dump_err:
                logger.warning(f"[XJEdu] ä¿å­˜ AI è¾“å…¥HTMLå¤±è´¥: {dump_err}")
        else:
            try:
                snippet = self._extract_relevant_snippet(body)
                lines = [f"æ ‡é¢˜ï¼š{title}"]
                lines.append("æ­£æ–‡ç‰‡æ®µï¼ˆçº¯æ–‡æœ¬ï¼‰ï¼š")
                lines.append(snippet)
                user_content = "\n".join([prompt_text] + lines)
            except Exception:
                user_content = f"{prompt_text}\næ ‡é¢˜ï¼š{title}\næ­£æ–‡ï¼ˆçº¯æ–‡æœ¬ï¼‰ï¼š\n{body[:4000]}"
        # ä¿å­˜å‘é€ç»™ AI çš„åŸæ–‡ï¼Œå¹¶åœ¨æ—¥å¿—ä¸­æç¤ºè·¯å¾„
        input_path = os.path.join(os.path.dirname(__file__), "ai_input_last.txt")
        try:
            with open(input_path, "w", encoding="utf-8", errors="ignore") as f:
                f.write(user_content)
            logger.warning(f"[XJEdu] AI è¾“å…¥å·²ä¿å­˜ {input_path}")
        except Exception as dump_err:
            logger.warning(f"[XJEdu] ä¿å­˜ AI è¾“å…¥å¤±è´¥: {dump_err}")
        payload = {
            "model": model,
            "temperature": 0,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¿¡æ¯æŠ½å–åŠ©æ‰‹ï¼Œä¸¥æ ¼æŒ‰ç”¨æˆ·æ¶ˆæ¯ä¸­çš„è¦æ±‚è¾“å‡º JSONã€‚"},
                {"role": "user", "content": user_content},
            ],
        }
        # å¯¹ deepseek-reasoner æ·»åŠ æ¨ç†å‚æ•°ï¼ˆå…¼å®¹æ€§å®‰å…¨ï¼‰
        try:
            if isinstance(model, str) and "reasoner" in model:
                payload["reasoning"] = {"effort": "medium"}
        except Exception:
            pass
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }
        try:
            async with aiohttp.ClientSession(headers=headers) as sess:
                async with sess.post(url, json=payload, timeout=60) as resp:
                    if resp.status != 200:
                        try:
                            resp_text = await resp.text(errors="ignore")
                        except Exception:
                            resp_text = ""
                        logger.warning(f"[XJEdu] AI è§£æå¤±è´¥ status={resp.status} url={url} resp={resp_text[:300]}")
                        return None
                    data = await resp.json()
            content = (((data.get("choices") or [{}])[0]).get("message") or {}).get("content") or ""
            # è°ƒè¯•é˜¶æ®µï¼šä¿å­˜ä¸è¾“å‡ºåŸå§‹å›å¤
            debug_path = os.path.join(os.path.dirname(__file__), "ai_last_response.json")
            try:
                existing: List[Dict[str, Any]] = []
                if os.path.exists(debug_path):
                    try:
                        with open(debug_path, "r", encoding="utf-8") as rf:
                            existing_data = json.load(rf)
                            if isinstance(existing_data, list):
                                existing = existing_data
                    except Exception:
                        existing = []
                existing.append({
                    "title": title,
                    "preview_body": body[:500],
                    "raw": content,
                    "api": {"base_url": base_url, "model": model},
                    "created_at": _now().isoformat(),
                })
                with open(debug_path, "w", encoding="utf-8") as f:
                    json.dump(existing[-200:], f, ensure_ascii=False, indent=2)
            except Exception as werr:
                logger.warning(f"[XJEdu] å†™å…¥ AI è°ƒè¯•æ–‡ä»¶å¤±è´¥: {werr}")
            # å°è¯•è§£æ JSON
            try:
                import json as _json

                text = content.strip()
                # æˆªå–å¯èƒ½çš„ä»£ç å—
                if text.startswith("```"):
                    text = text.strip("`")
                    text = text.split("\n", 1)[-1]
                parsed = _json.loads(text)
            except Exception:
                logger.warning(f"[XJEdu] AI è¿”å›æ— æ³•è§£æï¼Œå†…å®¹={content[:200]}")
                return None
            return parsed if isinstance(parsed, dict) else None
        except Exception as e:
            logger.warning(f"[XJEdu] AI è¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {e}")
            return None

    async def _load_store_file(self):
        if self.store_loaded:
            return
        if not os.path.exists(STORE_PATH):
            self.store_loaded = True
            return
        try:
            with open(STORE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            last_ids = data.get("last_seen_ids", [])
            kb = data.get("competitions", [])
            if last_ids:
                await self._save_kv("last_seen_ids", last_ids)
            if kb:
                await self._save_kv("competitions", kb)
            self.store_loaded = True
            logger.info("[XJEdu] å·²ä»å¤–ç½®æ–‡ä»¶åŠ è½½å†å²ç«èµ›æ•°æ®")
        except Exception as e:
            logger.warning(f"[XJEdu] è¯»å–å¤–ç½®å­˜å‚¨å¤±è´¥: {e}")
            self.store_loaded = True

    async def _save_store_file(self):
        try:
            data = {
                "last_seen_ids": await self._get_kv("last_seen_ids", []),
                "competitions": await self._get_kv("competitions", []),
                "errors": await self._get_kv("errors", []),
            }
            with open(STORE_PATH, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"[XJEdu] å†™å…¥å¤–ç½®å­˜å‚¨å¤±è´¥: {e}")

    async def _initial_sync(self):
        try:
            items = await self._fetch_competition_list()
            if not items:
                return
            last_ids: List[str] = await self._get_kv("last_seen_ids", [])
            kb: List[Dict[str, Any]] = await self._get_kv("competitions", [])
            updated = False
            for it in items:
                if it["id"] in last_ids:
                    continue
                detail = await self._fetch_detail(it.get("url", "")) if it.get("url") else {}
                title = it.get("title", "")
                body = detail.get("body", "")
                raw_html = detail.get("html", "")
                ai_res = await self._ai_extract_competition(title, body, raw_html)
                if not ai_res:
                    continue
                is_reg = bool(ai_res.get("is_registration", False))
                tw_start = _parse_date(ai_res.get("start_date")) if ai_res.get("start_date") else None
                tw_end = _parse_date(ai_res.get("end_date")) if ai_res.get("end_date") else None
                tw = {"start": tw_start, "end": tw_end}
                qq = _extract_qq_group(body)
                # ä»…åœ¨æ­£æ–‡åŒ…å«â€œå³æ—¥èµ·â€ç­‰æè¿°æ—¶ï¼Œä½¿ç”¨åˆ—è¡¨æ—¥æœŸä½œä¸ºæŠ¥åå¼€å§‹æ—¶é—´
                if is_reg and (tw.get("start") is None) and ("å³æ—¥èµ·" in body):
                    hint_dt = _parse_date(it.get("post_time") or "")
                    if hint_dt:
                        tw["start"] = hint_dt
                comp = {
                    "id": it["id"],
                    "title": title,
                    "url": it.get("url"),
                    "post_time": it.get("post_time"),
                    "is_registration": is_reg,
                    "start_date": tw["start"].isoformat() if tw["start"] else None,
                    "end_date": tw["end"].isoformat() if tw["end"] else None,
                    "qq_group": qq,
                    "created_at": _now().isoformat(),
                    "last_remind": None,
                }
                # é”™è¯¯ç›®å½•ï¼šè‹¥ä¸ºæŠ¥åä½†å¼€å§‹ä¸æˆªæ­¢æ—¥æœŸç›¸åŒæˆ–æˆªæ­¢æ—©äºå¼€å§‹ï¼Œè®¡å…¥é”™è¯¯ç›®å½•
                try:
                    errors: List[Dict[str, Any]] = await self._get_kv("errors", [])
                    sd = comp.get("start_date")
                    ed = comp.get("end_date")
                    def _d(s: Optional[str]) -> Optional[datetime]:
                        try:
                            return datetime.fromisoformat(s) if s else None
                        except Exception:
                            return None
                    sdt = _d(sd)
                    edt = _d(ed)
                    same_day = (sd and ed and sd[:10] == ed[:10])
                    end_before_start = (sdt and edt and edt < sdt)
                    if comp.get("is_registration") and (same_day or end_before_start):
                        errors.append({
                            "id": comp["id"],
                            "title": comp["title"],
                            "url": comp.get("url"),
                            "reason": "start_equals_end" if same_day else "end_before_start",
                            "start_date": sd,
                            "end_date": ed,
                            "created_at": _now().isoformat(),
                        })
                        await self._save_kv("errors", errors[-200:])
                except Exception:
                    pass
                if is_reg and tw["end"] and tw["end"] > _now():
                    kb = [k for k in kb if k.get("id") != comp["id"]]
                    kb.append(comp)
                    updated = True
                last_ids.append(it["id"])
            if last_ids:
                await self._save_kv("last_seen_ids", last_ids[-200:])
            if updated:
                await self._save_kv("competitions", kb)
                await self._save_store_file()
            logger.info("[XJEdu] åˆå§‹åŒæ­¥å®Œæˆï¼Œè¡¥å……çŸ¥è¯†åº“")
        except Exception as e:
            logger.warning(f"[XJEdu] åˆå§‹åŒæ­¥å¼‚å¸¸: {e}")

    async def _periodic_check_loop(self, interval_sec: int):
        while self._running:
            try:
                await self._check_and_push()
            except Exception as e:
                logger.warning(f"[XJEdu] å®šæ—¶æ£€æŸ¥å¼‚å¸¸: {e}")
            await asyncio.sleep(interval_sec)

    async def _daily_deadline_remind_loop(self, hour: int = 9):
        # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡æ˜¯å¦åˆ°ç‚¹ï¼Œé¿å…é˜»å¡
        while self._running:
            try:
                now = _now()
                if now.hour == hour and now.minute in (0, 1):
                    await self._send_deadline_reminders(days_threshold=3)
                    await asyncio.sleep(120)
            except Exception as e:
                logger.warning(f"[XJEdu] æˆªæ­¢æé†’å¼‚å¸¸: {e}")
            await asyncio.sleep(60)

    async def _check_and_push(self):
        items = await self._fetch_competition_list()
        if not items:
            return
        last_ids: List[str] = await self._get_kv("last_seen_ids", [])
        subscribers: List[str] = await self._get_kv("subscribers", [])
        kb: List[Dict[str, Any]] = await self._get_kv("competitions", [])

        new_items = [i for i in items if i["id"] not in last_ids]
        if not new_items:
            return

        for it in new_items:
            detail = await self._fetch_detail(it["url"]) if it.get("url") else {}
            title = it.get("title", "")
            body = detail.get("body", "")
            raw_html = detail.get("html", "")
            ai_res = await self._ai_extract_competition(title, body, raw_html)
            if not ai_res:
                continue
            is_reg = bool(ai_res.get("is_registration", False))
            tw_start = _parse_date(ai_res.get("start_date")) if ai_res.get("start_date") else None
            tw_end = _parse_date(ai_res.get("end_date")) if ai_res.get("end_date") else None
            tw = {"start": tw_start, "end": tw_end}
            qq = _extract_qq_group(body)
            # ä»…åœ¨æ­£æ–‡åŒ…å«â€œå³æ—¥èµ·â€ç­‰æè¿°æ—¶ï¼Œä½¿ç”¨åˆ—è¡¨æ—¥æœŸä½œä¸ºæŠ¥åå¼€å§‹æ—¶é—´
            if is_reg and (tw.get("start") is None) and ("å³æ—¥èµ·" in body):
                hint_dt = _parse_date(it.get("post_time") or "")
                if hint_dt:
                    tw["start"] = hint_dt

            comp = {
                "id": it["id"],
                "title": title,
                "url": it.get("url"),
                "post_time": it.get("post_time"),
                "is_registration": is_reg,
                "start_date": tw["start"].isoformat() if tw["start"] else None,
                "end_date": tw["end"].isoformat() if tw["end"] else None,
                "qq_group": qq,
                "created_at": _now().isoformat(),
                "last_remind": None,
            }
            # é”™è¯¯ç›®å½•ï¼šè‹¥ä¸ºæŠ¥åä½†å¼€å§‹ä¸æˆªæ­¢æ—¥æœŸç›¸åŒæˆ–æˆªæ­¢æ—©äºå¼€å§‹ï¼Œè®¡å…¥é”™è¯¯ç›®å½•
            try:
                errors: List[Dict[str, Any]] = await self._get_kv("errors", [])
                sd = comp.get("start_date")
                ed = comp.get("end_date")
                def _d(s: Optional[str]) -> Optional[datetime]:
                    try:
                        return datetime.fromisoformat(s) if s else None
                    except Exception:
                        return None
                sdt = _d(sd)
                edt = _d(ed)
                same_day = (sd and ed and sd[:10] == ed[:10])
                end_before_start = (sdt and edt and edt < sdt)
                if comp.get("is_registration") and (same_day or end_before_start):
                    errors.append({
                        "id": comp["id"],
                        "title": comp["title"],
                        "url": comp.get("url"),
                        "reason": "start_equals_end" if same_day else "end_before_start",
                        "start_date": sd,
                        "end_date": ed,
                        "created_at": _now().isoformat(),
                    })
                    await self._save_kv("errors", errors[-200:])
            except Exception:
                pass
            # æ›´æ–°çŸ¥è¯†åº“ï¼šè‹¥ä¸ºæŠ¥åä¸”å°šå¤„åœ¨æŠ¥åé˜¶æ®µï¼ŒåŠ å…¥KB
            if is_reg and ((tw["end"] and tw["end"] > _now()) or tw["end"] is None):
                # å»é‡æ›´æ–°
                kb = [k for k in kb if k.get("id") != comp["id"]]
                kb.append(comp)
            else:
                pass

            await self._broadcast_competition(comp, subscribers)

        if not new_items:
            pass

        # æ›´æ–° last_seen ä¸ KB
        last_ids.extend([i["id"] for i in new_items])
        await self._save_kv("last_seen_ids", last_ids[-200:])
        await self._save_kv("competitions", kb)
        await self._save_store_file()

    async def _broadcast_competition(self, comp: Dict[str, Any], subscribers: List[str]):
        # ä»…æ¨é€æŠ¥åç±»ä¿¡æ¯ï¼ŒéæŠ¥åé€šçŸ¥ç›´æ¥è·³è¿‡
        if not comp.get("is_registration"):
            return
        # ç»„è£…æ¨é€æ–‡æœ¬ï¼ˆæŠ¥åä¿¡æ¯ï¼‰
        lines = [f"ã€ç«èµ›æŠ¥åã€‘{comp.get('title','')}"]
        if comp.get("url"):
            lines.append(f"é“¾æ¥ï¼š{comp['url']}")
        sd = comp.get("start_date")
        ed = comp.get("end_date")
        if sd:
            lines.append(f"å¼€å§‹æ—¶é—´ï¼š{sd[:10]}")
        if ed:
            lines.append(f"æˆªæ­¢æ—¶é—´ï¼š{ed[:10]}")
        if comp.get("qq_group"):
            lines.append(f"ç«èµ›QQç¾¤ï¼š{comp['qq_group']}")
        msg = self._persona_wrap("\n".join(lines))

        chain = MessageChain().message(msg)
        for sess in subscribers:
            try:
                await self.context.send_message(sess, chain)
            except Exception as e:
                logger.warning(f"[XJEdu] æ¨é€å¤±è´¥ {sess}: {e}")

    async def _send_deadline_reminders(self, days_threshold: int = 3):
        subscribers: List[str] = await self._get_kv("subscribers", [])
        kb: List[Dict[str, Any]] = await self._get_kv("competitions", [])
        if not kb or not subscribers:
            return
        now = _now()
        for comp in kb:
            ed = comp.get("end_date")
            if not ed:
                continue
            try:
                end_dt = datetime.fromisoformat(ed)
            except Exception:
                continue
            days_left = (end_dt.date() - now.date()).days
            if 0 <= days_left <= days_threshold:
                # é˜²é‡æ¨ï¼šåŒä¸€å¤©åªæ¨ä¸€æ¬¡
                last_remind = comp.get("last_remind")
                if last_remind and last_remind[:10] == now.date().isoformat():
                    continue
                msg = (
                    f"ã€æŠ¥åæé†’ã€‘{comp.get('title','')}\n"
                    f"æŠ¥åæˆªè‡³ï¼š{end_dt.date().isoformat()}\n"
                    f"å‰©ä½™å¤©æ•°ï¼š{days_left}å¤©"
                )
                chain = MessageChain().message(self._persona_wrap(msg))
                for sess in subscribers:
                    try:
                        await self.context.send_message(sess, chain)
                    except Exception as e:
                        logger.warning(f"[XJEdu] æˆªæ­¢æé†’å¤±è´¥ {sess}: {e}")
                comp["last_remind"] = now.isoformat()
        await self._save_kv("competitions", kb)
        await self._save_store_file()

    async def _fetch_html(self, url: str) -> str:
        if not aiohttp:
            return ""
        # æ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å–ä»£ç†ï¼Œæå‡é€šè¿‡ç‡
        proxy = os.getenv("ASTRBOT_HTTP_PROXY") or os.getenv("HTTP_PROXY")
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Referer": "https://due.xjtu.edu.cn/",
        }
        async with aiohttp.ClientSession(headers=headers) as sess:
            try:
                async with sess.get(url, timeout=20, proxy=proxy) as resp:
                    text = await resp.text(errors="ignore")
                    # ç«™ç‚¹å¯èƒ½æœ‰JSåŠ¨æ€éªŒè¯ï¼Œè‹¥æ£€æµ‹åˆ°challengeåˆ™å°è¯•æµè§ˆå™¨æ¸²æŸ“å…œåº•
                    if "dynamic_challenge" in text or resp.status in (403, 429):
                        if not self._challenge_warned:
                            preview = text[:200].replace("\n", " ")
                            logger.warning(
                                f"[XJEdu] é‡åˆ°åŠ¨æ€æŒ‘æˆ˜æˆ–é™æµï¼Œå°è¯•ä½¿ç”¨ Playwright æ¸²æŸ“ã€‚status={resp.status} preview={preview}"
                            )
                            self._challenge_warned = True
                        rendered = await self._fetch_html_playwright(url, proxy)
                        return rendered or ""
                    return text
            except Exception as e:
                logger.exception(f"[XJEdu] æŠ“å–å¤±è´¥: {e}")
                return ""

    async def _fetch_html_playwright(self, url: str, proxy: Optional[str] = None) -> str:
        if not async_playwright:
            logger.warning("[XJEdu] Playwright æœªå®‰è£…ï¼Œæ— æ³•æ‰§è¡ŒåŠ¨æ€æ¸²æŸ“ã€‚å¯é€šè¿‡ pip install playwright && playwright install chromium å®‰è£…ã€‚")
            return ""
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True, proxy={"server": proxy} if proxy else None)
                context = await browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36",
                    locale="zh-CN",
                )
                page = await context.new_page()
                await page.goto(url, wait_until="networkidle", timeout=20000)
                # ç­‰å¾…é¡µé¢æ‰§è¡ŒæŒ‘æˆ˜ä¸è·³è½¬ï¼Œé€‚åº¦ç­‰å¾…å³å¯
                await page.wait_for_timeout(4000)
                content = await page.content()
                # è‹¥ä»åŒ…å« challenge å…³é”®å­—ï¼Œå†å¤šç­‰ä¸€è½®
                if "dynamic_challenge" in content or "å®‰å…¨æ£€æŸ¥" in content:
                    await page.wait_for_timeout(4000)
                    content = await page.content()
                # é¦–æ¬¡æ¸²æŸ“è½ç›˜ï¼Œä¾¿äºäººå·¥æ£€æŸ¥ç»“æ„
                if not self._render_dumped:
                    dump_path = os.path.join(os.path.dirname(__file__), "debug_rendered.html")
                    try:
                        with open(dump_path, "w", encoding="utf-8", errors="ignore") as f:
                            f.write(content)
                    except Exception as dump_err:
                        logger.warning(f"[XJEdu] æ¸²æŸ“ç»“æœè½ç›˜å¤±è´¥: {dump_err}")
                    self._render_dumped = True
                await browser.close()
                return content
        except Exception as e:
            logger.exception(f"[XJEdu] Playwright æ¸²æŸ“å¤±è´¥: {e}")
            return ""

    async def _fetch_competition_list(self) -> List[Dict[str, Any]]:
        # å¤šå…¥å£æŠ“å– + æœ¬åœ°å›é€€
        html_list: List[tuple[str, str]] = []
        main_html = await self._fetch_html(DUE_LIST_URL)
        if main_html:
            html_list.append((main_html, DUE_LIST_URL))
        for u in DUE_LIST_EXTRA:
            h = await self._fetch_html(u)
            if h:
                html_list.append((h, u))

        # æœ¬åœ°å›é€€ï¼šåŒç›®å½• source_code.html æˆ–ç¯å¢ƒå˜é‡ ASTRBOT_XJTU_FALLBACK_HTML æŒ‡å‘çš„æ–‡ä»¶
        if not html_list:
            local_path = os.getenv("ASTRBOT_XJTU_FALLBACK_HTML") or os.path.join(os.path.dirname(__file__), "source_code.html")
            if os.path.exists(local_path):
                try:
                    with open(local_path, "r", encoding="utf-8", errors="ignore") as f:
                        html_list.append((f.read(), "file://fallback"))
                    logger.info(f"[XJEdu] ä½¿ç”¨æœ¬åœ°HTMLå›é€€: {local_path}")
                except Exception as e:
                    logger.warning(f"[XJEdu] è¯»å–æœ¬åœ°å›é€€HTMLå¤±è´¥: {e}")

        items: Dict[str, Dict[str, Any]] = {}
        if not BeautifulSoup:
            return []

        for html, base in html_list:
            parsed = self._parse_list_html(html, base)
            for it in parsed:
                items[it["id"]] = it

        if not items and not main_html:
            logger.warning("[XJEdu] æœªè·å–åˆ°é¡µé¢HTMLï¼Œå¯èƒ½è¢«åçˆ¬æˆ–ç½‘ç»œå¼‚å¸¸ã€‚")
        return list(items.values())

    def _parse_list_html(self, html: str, base_url: str) -> List[Dict[str, Any]]:
        soup = BeautifulSoup(html, "html.parser")
        found: List[Dict[str, Any]] = []
        # ä¼˜å…ˆè§£æåˆ—è¡¨ ul.list li a span
        for li in soup.select("ul.list li"):
            a = li.find("a")
            date_span = li.find("span")
            if not a or not a.get("href"):
                continue
            title = (a.get_text() or "").strip()
            href = a.get("href").strip()
            # è¿‡æ»¤å…³é”®è¯ï¼Œæ”¾å®½åˆ°å« ç«èµ›/æ¯”èµ›/æŠ¥å/ç«èµ›å¤§åˆ›/ç«èµ›å®‰æ’
            if not any(k in title for k in ["ç«èµ›", "æ¯”èµ›", "æŠ¥å", "å¤§åˆ›", "èµ›"]):
                continue
            url = href if href.startswith("http") else self._normalize_url(base_url, href)
            post_time = (date_span.get_text() or "").strip() if date_span else None
            found.append({
                "id": url,
                "title": title,
                "url": url,
                "post_time": post_time,
            })
        # å…œåº•ï¼šå…¨å±€é“¾æ¥æ‰«æ
        if not found:
            for a in soup.find_all("a", href=True):
                title = (a.get_text() or "").strip()
                href = a["href"].strip()
                if not title:
                    continue
                if not any(k in title for k in ["ç«èµ›", "æ¯”èµ›", "æŠ¥å", "å¤§åˆ›", "èµ›"]):
                    continue
                url = href if href.startswith("http") else self._normalize_url(base_url, href)
                found.append({
                    "id": url,
                    "title": title,
                    "url": url,
                    "post_time": None,
                })
        return found

    def _normalize_url(self, base_url: str, href: str) -> str:
        if href.startswith("http"):
            return href
        if href.startswith("../"):
            # å»æ‰ ../
            href = href[3:]
        if href.startswith("./"):
            href = href[2:]
        # åŸºç¡€åŸŸ
        if base_url.startswith("http"):
            root = "https://due.xjtu.edu.cn/"
            return root + href.lstrip("/")
        return href

    async def _fetch_detail(self, url: str) -> Dict[str, Any]:
        html = await self._fetch_html(url)
        if not html or not BeautifulSoup:
            return {"body": "", "html": html or ""}
        soup = BeautifulSoup(html, "html.parser")
        # ä¼˜å…ˆä»æ­£æ–‡å®¹å™¨æŠ½å–
        candidates = []
        selectors = [
            "div#ny-main", "div.ny", "div#vsb_content", "div#vsb_content_2",
            "div#vsb_content_4", "div#vsb_content_5", "div.article", "div.content",
            "div.news-content"
        ]
        for sel in selectors:
            candidates.extend(soup.select(sel))
        best_text = ""
        for el in candidates:
            t = el.get_text("\n", strip=True)
            if len(t) > len(best_text):
                best_text = t
        if not best_text:
            best_text = soup.get_text("\n")
        return {"body": best_text, "html": html}

    def _extract_relevant_snippet(self, body: str) -> str:
        lines = [ln.strip() for ln in (body or "").splitlines()]
        patt_date = re.compile(r"\d{4}[å¹´./-]\d{1,2}[æœˆ./-]\d{1,2}")
        include_kw = ["æŠ¥å", "æŠ¥åé€šçŸ¥", "æŠ¥åå¼€å§‹", "æŠ¥åæˆªæ­¢", "å‚èµ›", "ç«èµ›", "å®‰æ’", "æˆªæ­¢æ—¶é—´", "å¼€å§‹æ—¶é—´", "æŠ¥åæ—¶é—´", "å‘å¸ƒæ—¥æœŸ", "å‘å¸ƒ"]
        discard_kw = ["å½“å‰ä½ç½®", "ä¸Šä¸€ç¯‡", "ä¸‹ä¸€ç¯‡", "æ‰“å°", "åˆ†äº«", "è¿”å›", "é˜…è¯»", "æµè§ˆæ¬¡æ•°", "æ¥æº", "ä½œè€…"]
        picked = []
        for ln in lines:
            if not ln:
                continue
            # æ’é™¤æ˜æ˜¾çš„å¯¼èˆª/é¡µçœ‰é¡µè„šç­‰æ— å…³å†…å®¹
            if any(k in ln for k in discard_kw) and not any(k in ln for k in include_kw):
                continue
            # æ”¶å…¥åŒ…å«æ—¥æœŸæˆ–å…³é”®æŠ¥åè¯çš„è¡Œ
            if patt_date.search(ln) or any(k in ln for k in include_kw):
                picked.append(ln)
            if len(picked) >= 60:
                break
        return "\n".join(picked if picked else lines[:60])

    async def _send_welcome_with_latest(self):
        subscribers: List[str] = await self._get_kv("subscribers", [])
        if not subscribers:
            return
        items = await self._fetch_competition_list()
        latest = items[0] if items else None
        greeting = "ğŸ¤– XJEdu ç«èµ›ç›‘æ§å·²ä¸Šçº¿ï¼Œå¼€å§‹ä¸ºæ‚¨ç›‘å¬æ•™åŠ¡å¤„é€šçŸ¥ã€‚"
        msg_lines = [greeting]
        if latest:
            msg_lines.append("æœ€æ–°é€šçŸ¥ç¤ºä¾‹ï¼š")
            msg_lines.append(f"- {latest.get('title','')}")
            if latest.get("url"):
                msg_lines.append(f"  é“¾æ¥ï¼š{latest['url']}")
        chain = MessageChain().message("\n".join(msg_lines))
        for sess in subscribers:
            try:
                await self.context.send_message(sess, MessageChain().message(self._persona_wrap("\n".join(msg_lines))))
            except Exception as e:
                logger.warning(f"[XJEdu] ä¸Šçº¿é—®å€™å‘é€å¤±è´¥ {sess}: {e}")

    # ==================== æŒ‡ä»¤ç»„ï¼šç«èµ›ï¼ˆè‹±æ–‡çŸ­å compï¼‰ ====================
    @filter.command_group("comp")
    def competition_group(self):
        """Competition commands"""
        pass

    @competition_group.command("sub")
    async def cmd_subscribe(self, event: AstrMessageEvent):
        sess = event.unified_msg_origin
        subs: List[str] = await self._get_kv("subscribers", [])
        if sess in subs:
            yield event.plain_result(self._persona_wrap("å·²è®¢é˜…ï¼Œæ— éœ€é‡å¤æ“ä½œ"))
            return
        subs.append(sess)
        await self._save_kv("subscribers", subs)
        yield event.plain_result(self._persona_wrap("âœ… å·²è®¢é˜…ç«èµ›æ¨é€"))

    @competition_group.command("unsub")
    async def cmd_unsubscribe(self, event: AstrMessageEvent):
        sess = event.unified_msg_origin
        subs: List[str] = await self._get_kv("subscribers", [])
        if sess not in subs:
            yield event.plain_result(self._persona_wrap("æœªè®¢é˜…"))
            return
        subs = [s for s in subs if s != sess]
        await self._save_kv("subscribers", subs)
        yield event.plain_result(self._persona_wrap("âœ… å·²é€€è®¢ç«èµ›æ¨é€"))

    @competition_group.command("list")
    async def cmd_list(self, event: AstrMessageEvent):
        kb: List[Dict[str, Any]] = await self._get_kv("competitions", [])
        errors: List[Dict[str, Any]] = await self._get_kv("errors", [])
        if not kb:
            tip = "ğŸ“‹ å½“å‰æš‚æ— æ­£åœ¨æŠ¥åçš„ç«èµ›"
            if errors:
                tip += f"\nâš ï¸ é”™è¯¯ç›®å½•ï¼š{len(errors)} æ¡ï¼ˆå¯åœ¨æœ¬åœ°å­˜å‚¨ä¸­ä¿®å¤ï¼‰"
            yield event.plain_result(self._persona_wrap(tip))
            return
        lines = ["ğŸ“‹ å½“å‰å¯æŠ¥åç«èµ›ï¼š"]
        if errors:
            lines.append(f"âš ï¸ é”™è¯¯ç›®å½•ï¼š{len(errors)} æ¡ï¼ˆå¯åœ¨æœ¬åœ°å­˜å‚¨ä¸­ä¿®å¤ï¼‰")
        kb_sorted = sorted(
            kb,
            key=lambda x: x.get("end_date") or "9999-12-31",
        )
        for c in kb_sorted:
            ed = c.get("end_date")
            title = c.get("title")
            url = c.get("url")
            line = f"- {title}"
            if ed:
                try:
                    line += f" | æˆªæ­¢: {datetime.fromisoformat(ed).date().isoformat()}"
                except Exception:
                    pass
            if url:
                line += f"\n  é“¾æ¥: {url}"
            if c.get("qq_group"):
                line += f"\n  QQç¾¤: {c['qq_group']}"
            lines.append(line)
        yield event.plain_result(self._persona_wrap("\n".join(lines)))

    @competition_group.command("check")
    async def cmd_check(self, event: AstrMessageEvent):
        await self._check_and_push()
        yield event.plain_result(self._persona_wrap("âœ… å·²å®Œæˆä¸€æ¬¡å³æ—¶æ£€æŸ¥"))

    # ==================== æŒ‡ä»¤ç»„ï¼šç®¡ç†ï¼ˆè‹±æ–‡çŸ­å cadminï¼‰ ====================
    @filter.command_group("cadmin")
    def manage_group(self):
        """Competition admin commands"""
        pass

    @manage_group.command("ai")
    async def cmd_ai_toggle(self, event: AstrMessageEvent, mode: str = ""):
        """AI æ£€æµ‹å¼€å…³ã€‚ç”¨æ³•ï¼š/ç«èµ›ç®¡ç† ai on|off"""
        mode = (mode or "").strip().lower()
        if mode in ("on", "off", "å¼€å¯", "å…³é—­"):
            flag = mode in ("on", "å¼€å¯")
            await self._save_kv("ai_use", flag)
            yield event.plain_result(self._persona_wrap(f"AI è§£æå·²{'å¼€å¯' if flag else 'å…³é—­'}"))
            return
        # æ˜¾ç¤ºå½“å‰çŠ¶æ€
        enabled = await self._is_ai_enabled()
        yield event.plain_result(self._persona_wrap(f"AI è§£æå½“å‰çŠ¶æ€ï¼š{'å¼€å¯' if enabled else 'å…³é—­'}\nç”¨æ³•ï¼š/ç«èµ›ç®¡ç† ai on|off"))

    @manage_group.command("init")
    async def cmd_manual_init(self, event: AstrMessageEvent):
        """æ‰‹åŠ¨åˆå§‹åŒ–ï¼šä»æ•™åŠ¡å¤„æ‹‰å–å¹¶è¡¥å……çŸ¥è¯†åº“ï¼ˆä¸æ¨é€å†å²ï¼‰ã€‚"""
        try:
            items = await self._fetch_competition_list()
            if not items:
                yield event.plain_result(self._persona_wrap("âš ï¸ åˆå§‹åŒ–å¤±è´¥ï¼šæœªæŠ“å–åˆ°ç«èµ›åˆ—è¡¨ï¼ˆå¯èƒ½è¢«åçˆ¬æˆ–ç½‘ç»œå¼‚å¸¸ï¼‰"))
                return
            await self._initial_sync()
            latest = items[0]
            lines = ["âœ… å·²å®Œæˆåˆå§‹åŒ–åŒæ­¥", "æœ€æ–°æŠ“å–ï¼š", f"- {latest.get('title','')}"]
            if latest.get("url"):
                lines.append(f"  é“¾æ¥ï¼š{latest['url']}")
            yield event.plain_result(self._persona_wrap("\n".join(lines)))
        except Exception as e:
            yield event.plain_result(self._persona_wrap(f"âš ï¸ åˆå§‹åŒ–å¼‚å¸¸ï¼š{e}"))

    @manage_group.command("aitest")
    async def cmd_ai_test(self, event: AstrMessageEvent):
        """AI è¿é€šæ€§æ£€æµ‹ï¼šè¯·æ±‚ä¸€æ¬¡æŠ½å–å¹¶å±•ç¤ºå›å¤é¢„è§ˆã€‚"""
        try:
            enabled = await self._is_ai_enabled()
            if not enabled:
                yield event.plain_result(self._persona_wrap("AI å½“å‰ä¸ºå…³é—­ï¼Œå¯ç”¨ /cadmin ai on å¼€å¯"))
                return
            sample_title = "å…³äºä¸¾åŠ2026å¹´æŸæŸç«èµ›çš„é€šçŸ¥"
            sample_body = "æŠ¥åæ—¶é—´ï¼š2026-02-01 è‡³ 2026-02-20ã€‚å‚èµ›å¯¹è±¡ä¸ºå…¨ä½“æœ¬ç§‘ç”Ÿã€‚"
            res = await self._ai_extract_competition(sample_title, sample_body)
            if not res:
                yield event.plain_result(self._persona_wrap("âš ï¸ AI è¯·æ±‚æˆ–è§£æå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—ä¸ ai_last_response.json"))
                return
            # ä¿å­˜åˆ°æ–‡ä»¶
            out_path = os.path.join(os.path.dirname(__file__), "ai_last_response.json")
            if os.path.exists(out_path):
                try:
                    with open(out_path, "r", encoding="utf-8") as f:
                        preview = f.read()[:200]
                except Exception:
                    preview = json.dumps(res, ensure_ascii=False)[:200]
            else:
                preview = json.dumps(res, ensure_ascii=False)[:200]
            logger.warning(f"[XJEdu] AI è¿é€šæ€§æ£€æµ‹è¿”å›: {preview}")
            yield event.plain_result(self._persona_wrap(f"âœ… AI è¿é€šæ€§æ­£å¸¸ï¼Œé¢„è§ˆï¼š\n{json.dumps(res, ensure_ascii=False, indent=2)}"))
        except Exception as e:
            yield event.plain_result(self._persona_wrap(f"âš ï¸ AI è¿é€šæ€§æ£€æµ‹å¼‚å¸¸ï¼š{e}"))

    @manage_group.command("reset")
    async def cmd_reset(self, event: AstrMessageEvent):
        """æ¸…ç©ºå·²è¯»ä¸ç¼“å­˜ï¼Œæ–¹ä¾¿é‡æ–°æ¨é€æµ‹è¯•ã€‚"""
        try:
            await self._save_kv("last_seen_ids", [])
            await self._save_kv("competitions", [])
            await self._save_kv("errors", [])
            # åˆ é™¤å¤–ç½®æ–‡ä»¶
            removed = False
            if os.path.exists(STORE_PATH):
                os.remove(STORE_PATH)
                removed = True
            msg = "âœ… å·²æ¸…ç©ºå·²è¯»ä¸ç¼“å­˜"
            if removed:
                msg += "ï¼Œå¹¶å·²åˆ é™¤æœ¬åœ°å­˜å‚¨æ–‡ä»¶"
            else:
                msg += "ï¼ˆæœ¬åœ°å­˜å‚¨æ–‡ä»¶ä¸å­˜åœ¨ï¼‰"
            msg += "ï¼Œå¯å†æ¬¡ /comp check é‡æ‹‰æ¨é€"
            yield event.plain_result(self._persona_wrap(msg))
        except Exception as e:
            yield event.plain_result(self._persona_wrap(f"âš ï¸ é‡ç½®å¤±è´¥ï¼š{e}"))

    @manage_group.command("stopcheck")
    async def cmd_stop_check(self, event: AstrMessageEvent):
        """åœæ­¢å®šæ—¶æ£€æŸ¥ä»»åŠ¡ã€‚"""
        try:
            await self._stop_check_task()
            yield event.plain_result(self._persona_wrap("âœ… å·²åœæ­¢å®šæ—¶æ£€æŸ¥ä»»åŠ¡"))
        except Exception as e:
            yield event.plain_result(self._persona_wrap(f"âš ï¸ åœæ­¢å¤±è´¥ï¼š{e}"))

    # ==================== å¸®åŠ© ====================
    @filter.command("ç«èµ›å¸®åŠ©")
    async def cmd_help(self, event: AstrMessageEvent):
        lines = [
            "ğŸ“– ç«èµ›æ’ä»¶æŒ‡ä»¤æ€»è§ˆ",
            "åŸºç¡€æŒ‡ä»¤ç»„ï¼ˆcompï¼‰ï¼š",
            "  /comp sub           è®¢é˜…ç«èµ›æ¨é€ï¼ˆç¾¤/ç§èŠå‡å¯ï¼‰",
            "  /comp unsub         é€€è®¢ç«èµ›æ¨é€",
            "  /comp list          æŸ¥çœ‹å½“å‰å¯æŠ¥åç«èµ›",
            "  /comp check         ç«‹å³æŠ“å–ä¸€æ¬¡æ•™åŠ¡å¤„é€šçŸ¥",
            "  /ç«èµ›å¸®åŠ©            æŸ¥çœ‹æœ¬å¸®åŠ©",
            "ç®¡ç†æŒ‡ä»¤ç»„ï¼ˆcadminï¼‰ï¼š",
            "  /cadmin ai on|off      å¼€å…³AIè§£æå¹¶æŸ¥çœ‹çŠ¶æ€",
            "  /cadmin init           æ‰‹åŠ¨æ‰§è¡Œåˆå§‹åŒ–æ‹‰å–",
            "  /cadmin aitest         AI è¿é€šæ€§è‡ªæ£€ï¼ˆéœ€é…ç½®å¯†é’¥ï¼‰",
            "  /cadmin reset          æ¸…ç©ºç¼“å­˜ä¸æœ¬åœ°å­˜å‚¨",
            "  /cadmin stopcheck      åœæ­¢å®šæ—¶æ£€æŸ¥ä»»åŠ¡",
            "ä½¿ç”¨æç¤ºï¼šå‘½ä»¤å‰ç¼€ä¸æƒé™è§„åˆ™ä»¥æœºå™¨äººå…¨å±€é…ç½®ä¸ºå‡†ã€‚",
        ]
        yield event.plain_result(self._persona_wrap("\n".join(lines)))

